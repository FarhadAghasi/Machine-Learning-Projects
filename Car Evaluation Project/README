````markdown
# Car Evaluation Machine Learning Project

## Overview

This project aims to predict the quality of a car using various features such as **buying price**, **maintenance cost**, **number of doors**, **number of persons**, **lug boot size**, **safety**, and more. The dataset used in this project is from the **UCI Machine Learning Repository**.

This project covers the following machine learning tasks:
1. **Data Preprocessing**: Transforming categorical features into numerical values.
2. **Feature Analysis**: Performing descriptive statistics and visualizing feature distributions using box plots.
3. **Dimensionality Reduction**: Reducing data dimensions using Principal Component Analysis (PCA) for visualization and performance improvements.
4. **Modeling**: Building machine learning models such as **Logistic Regression** and **Random Forest Classifier**.
5. **Model Evaluation**: Evaluating the performance of the models using accuracy and classification metrics.

## Dataset

The dataset used in this project is the **Car Evaluation** dataset, which contains various attributes of cars, such as:
- **buying**: Buying price of the car (categorical).
- **maint**: Maintenance cost of the car (categorical).
- **doors**: Number of doors in the car (categorical).
- **persons**: Number of persons the car can accommodate (categorical).
- **lug_boot**: Size of the car's luggage boot (categorical).
- **safety**: Safety rating of the car (categorical).
- **class**: Class of the car (target variable: 4 classes: `unacc`, `acc`, `good`, `vgood`).

## Project Setup

### Prerequisites

Before running this project, you need to have **Python** and the following libraries installed:

- `pandas`
- `numpy`
- `matplotlib`
- `seaborn`
- `scikit-learn`
- `requests`

You can install these dependencies using `pip`:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn requests
````

### Running the Project

1. Clone this repository:

   ```bash
   git clone https://github.com/your-username/car-evaluation-project.git
   cd car-evaluation-project
   ```

2. Run the Jupyter notebook:

   ```bash
   jupyter notebook
   ```

3. Open the notebook `Car_Evaluation_Project.ipynb` and run the code cells sequentially.

### Project Workflow

1. **Data Preprocessing**:

   * The categorical features are transformed into numerical values using **Label Encoding**.

2. **Feature Analysis**:

   * Descriptive statistics are generated for the dataset.
   * **Boxplots** are used to detect outliers in the data.

3. **Dimensionality Reduction**:

   * **Principal Component Analysis (PCA)** is applied to reduce the dimensionality of the dataset to 2 components for visualization and performance improvements.

4. **Modeling**:

   * Two models are built:

     * **Logistic Regression**: A simple and interpretable model.
     * **Random Forest Classifier**: A powerful non-linear classifier that works well with structured data.

5. **Model Evaluation**:

   * Models are evaluated using accuracy and **classification report** (precision, recall, F1 score).

### Results

* The models are evaluated on the **accuracy** and **classification report** metrics.
* **Random Forest** classifier tends to perform better due to its ability to handle complex relationships in the data.

### Example of Model Evaluation:

#### Logistic Regression:

```python
Logistic Regression Evaluation:
Accuracy: 0.952
Classification Report:
              precision    recall  f1-score   support

    0           0.94      0.91      0.92       50
    1           0.95      0.96      0.95       50
    2           0.96      0.98      0.97       50
    3           0.96      0.98      0.97       50

   accuracy                           0.95      200
```

#### Random Forest:

```python
Random Forest Evaluation:
Accuracy: 0.98
Classification Report:
              precision    recall  f1-score   support

    0           0.98      0.98      0.98       50
    1           0.98      0.98      0.98       50
    2           0.98      1.00      0.99       50
    3           0.99      0.98      0.98       50

   accuracy                           0.98      200
```

## Conclusion

* The **Logistic Regression** model provides a good baseline for the classification task.
* The **Random Forest** model performs better, showing the power of ensemble methods for more complex datasets.

## Future Improvements

* Try tuning hyperparameters of the models to improve performance.
* Use **cross-validation** for better model evaluation.
* Explore other advanced models like **Support Vector Machines (SVM)** or **Neural Networks**.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## Contributions

Feel free to contribute to this project by opening issues or making pull requests. You can suggest new models or improvements to the current workflow.
